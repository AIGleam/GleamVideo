import os
import sys
import logging
import tempfile
import subprocess
import aiohttp
import uvicorn
import asyncio
import json
import random
import re
import io
import time

import numpy as np
import cv2
import pytz
from typing import Optional, List, Union, Tuple
from datetime import datetime
from typing import Optional, List
from fastapi import FastAPI, Request, UploadFile, Form
from fastapi.responses import HTMLResponse, JSONResponse
from pydantic import BaseModel
from PIL import Image

from selenium import webdriver
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.chrome.service import Service

# ---------------------------------------------------------------------------
# Logging with color
# ---------------------------------------------------------------------------
class ColorFormatter(logging.Formatter):
    grey = "\x1b[38;21m"
    blue = "\x1b[34;21m"
    yellow = "\x1b[33;21m"
    red = "\x1b[31;21m"
    bold_red = "\x1b[31;1m"
    reset = "\x1b[0m"

    fmt_str = "%(asctime)s - %(levelname)s - %(message)s"
    FORMATS = {
        logging.DEBUG: grey + fmt_str + reset,
        logging.INFO: blue + fmt_str + reset,
        logging.WARNING: yellow + fmt_str + reset,
        logging.ERROR: red + fmt_str + reset,
        logging.CRITICAL: bold_red + fmt_str + reset
    }

    def format(self, record):
        log_fmt = self.FORMATS.get(record.levelno, self.fmt_str)
        formatter = logging.Formatter(log_fmt, datefmt="%Y-%m-%d %H:%M:%S")
        return formatter.format(record)

logger = logging.getLogger(__name__)
logger.setLevel(logging.INFO)

console_handler = logging.StreamHandler(sys.stdout)
console_handler.setFormatter(ColorFormatter())
logger.addHandler(console_handler)

# ---------------------------------------------------------------------------
# Global progress tracking (naive)
# ---------------------------------------------------------------------------
progress_data = {
    "status": "idle",  # idle, working, done, error
    "message": "",
    "pct": 0
}

def update_progress(status: str, message: str, pct: float):
    progress_data["status"] = status
    progress_data["message"] = message
    progress_data["pct"] = pct

# ---------------------------------------------------------------------------
# Kokoro TTS
# ---------------------------------------------------------------------------
VOICE_COMMAND = "./kokoro-tts"  # Adjust if needed
DEFAULT_VOICE = "am_adam"
DEFAULT_LANGUAGE = "en-us"
DEFAULT_SPEED = 1.2

def generate_tts_kokoro(script_text: str, output_file: str, return_duration: bool = False) -> Union[bool, Tuple[bool, float]]:
    """
    Generate TTS using Kokoro TTS.
    If return_duration is True, returns (success, duration)
    """
    try:
        with tempfile.NamedTemporaryFile(mode='w', suffix='.txt', delete=False) as tmpf:
            tmpf.write(script_text)
            temp_text_path = tmpf.name

        cmd = [
            VOICE_COMMAND,
            temp_text_path,
            output_file,
            "--speed", str(DEFAULT_SPEED),
            "--lang", DEFAULT_LANGUAGE,
            "--voice", DEFAULT_VOICE
        ]
        logger.info(f"Running Kokoro TTS => {cmd}")
        proc = subprocess.run(cmd, capture_output=True, text=True)

        os.unlink(temp_text_path)

        if proc.returncode != 0:
            logger.error(f"TTS error => {proc.stderr}")
            return (False, 0.0) if return_duration else False
            
        if not os.path.exists(output_file):
            logger.error("TTS output file not created!")
            return (False, 0.0) if return_duration else False

        if return_duration:
            # Create a temporary instance just to get the duration
            temp_builder = KenBurnsVideoBuilder(1920, 1080)
            duration = temp_builder.get_audio_duration(output_file)
            return True, duration
        return True

    except Exception as e:
        logger.error(f"TTS generation exception => {e}")
        return (False, 0.0) if return_duration else False

# ---------------------------------------------------------------------------
# Simple Metadata Generation
# ---------------------------------------------------------------------------
async def generate_metadata_for_video(topic: str) -> dict:
    """
    Basic JSON metadata generation. Expand if needed.
    """
    safe_fn = re.sub(r'[^\w\s-]', '', topic)[:20].strip().replace(' ', '_')
    if not safe_fn:
        safe_fn = "video"
    return {
        "video_title": f"Amazing Video about {topic[:10]}...",
        "video_description": "Hashtags #Cool #Video #AutoGenerated",
        "safe_filename": safe_fn
    }

# ---------------------------------------------------------------------------
# KenBurnsVideoBuilder
# ---------------------------------------------------------------------------
class KenBurnsVideoBuilder:
    def __init__(self, width: int, height: int, fps: int = 60):
        self.width = width
        self.height = height
        self.fps = fps
        self.temp_files = [] 

    def _create_temp_file(self, suffix: str, output_folder: str) -> str:
        """Create a temporary file in the specified output folder"""
        temp_path = os.path.join(output_folder, f"temp_{int(time.time())}_{random.randint(1000, 9999)}{suffix}")
        self.temp_files.append(temp_path)
        return temp_path

    def cleanup_temp_files(self):
        """Clean up all temporary files"""
        for temp_file in self.temp_files:
            try:
                if os.path.exists(temp_file):
                    os.unlink(temp_file)
            except Exception as e:
                logger.warning(f"Failed to cleanup temp file {temp_file}: {e}")
        self.temp_files.clear()

    def get_audio_duration(self, path: str) -> float:
        """
        Return duration in seconds from an audio or video file.
        """
        try:
            cmd = ["ffmpeg", "-i", path]
            proc = subprocess.run(cmd, stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True)
            lines = proc.stderr.split("\n")
            dur_line = [l for l in lines if "Duration" in l]
            if not dur_line:
                return 0.0
            seg = dur_line[0].split("Duration:")[1].split(",")[0].strip()
            hh, mm, ss = seg.split(":")
            return float(hh)*3600 + float(mm)*60 + float(ss)
        except Exception as e:
            logger.error(f"Error reading audio duration => {e}")
            return 0.0

    def is_url(self, text: str) -> bool:
        """
        Check if the given text looks like an http(s) URL.
        """
        pat = re.compile(r'^https?://', re.IGNORECASE)
        return bool(pat.match(text.strip()))

    def load_local_image(self, path: str) -> np.ndarray:
        """
        Load an image from a local file path, fit it into (width,height),
        return BGR array or black if fails.
        """
        if not os.path.exists(path):
            logger.warning(f"Local file not found => {path}")
            return np.zeros((self.height, self.width, 3), dtype=np.uint8)
        try:
            pil_img = Image.open(path).convert("RGB")
            return self._fit_image(pil_img, self.width, self.height)
        except Exception as e:
            logger.error(f"Error loading local image => {e}")
            return np.zeros((self.height, self.width, 3), dtype=np.uint8)

    def screenshot_url(self, url: str) -> np.ndarray:
        """
        Enhanced Selenium screenshot with advanced anti-detection, popup handling,
        and proper resolution management.
        """
        try:
            # Advanced Chrome options for stealth
            opts = Options()
            opts.add_argument(f"--window-size={self.width},{self.height}")
            opts.add_argument("--headless=new")
            opts.add_argument("--no-sandbox")
            opts.add_argument("--disable-dev-shm-usage")
            opts.add_argument('--disable-blink-features=AutomationControlled')
            opts.add_argument('--disable-infobars')
            opts.add_argument('--ignore-certificate-errors')
            opts.add_argument('--allow-running-insecure-content')
            opts.add_argument('--disable-web-security')
            opts.add_argument('--disable-popup-blocking')
            
            # Random user agent
            user_agents = [
                'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
                'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
                'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36'
            ]
            opts.add_argument(f'user-agent={random.choice(user_agents)}')

            # Additional stealth preferences
            opts.add_experimental_option("excludeSwitches", ["enable-automation"])
            opts.add_experimental_option('useAutomationExtension', False)
            opts.add_experimental_option('prefs', {
                'profile.default_content_setting_values.notifications': 2,
                'profile.default_content_settings.popups': 0,
                'download.prompt_for_download': False,
                'download.default_directory': '/dev/null',
                'plugins.always_open_pdf_externally': True,
                'credentials_enable_service': False,
                'profile.password_manager_enabled': False
            })

            svc = Service("/usr/bin/chromedriver")
            driver = webdriver.Chrome(options=opts, service=svc)
            
            # Set window size based on content type (portrait/landscape)
            if self.height > self.width:  # Portrait mode
                driver.set_window_size(self.width, self.height)
            else:  # Landscape mode
                driver.set_window_size(self.width, self.height)

            # Stealth scripts
            stealth_js = """
                Object.defineProperty(navigator, 'webdriver', {get: () => undefined});
                window.chrome = { runtime: {} };
                Object.defineProperty(navigator, 'languages', {get: () => ['en-US', 'en']});
                Object.defineProperty(navigator, 'plugins', {get: () => [1, 2, 3, 4, 5]});
            """
            
            # Anti-popup and overlay scripts
            remove_elements_js = """
                function removeElements() {
                    // Common popup/overlay selectors
                    const selectors = [
                        '[class*="cookie"]', '[class*="popup"]', '[class*="modal"]',
                        '[class*="overlay"]', '[class*="drawer"]', '[id*="cookie"]',
                        '[id*="popup"]', '[id*="modal"]', '[id*="overlay"]',
                        '[class*="banner"]', '[class*="consent"]', '[class*="notification"]',
                        'div.fixed', 'div[role="dialog"]', '[class*="welcome"]',
                        '[class*="subscribe"]', '[class*="newsletter"]'
                    ];
                    
                    selectors.forEach(selector => {
                        document.querySelectorAll(selector).forEach(element => {
                            if (window.getComputedStyle(element).position === 'fixed' ||
                                window.getComputedStyle(element).position === 'sticky') {
                                element.remove();
                            }
                        });
                    });
                    
                    // Remove fixed/sticky positioning and overflow:hidden
                    document.body.style.position = 'static';
                    document.body.style.overflow = 'visible';
                    document.documentElement.style.overflow = 'visible';
                    
                    // Remove backdrop filters
                    document.querySelectorAll('*').forEach(el => {
                        if (window.getComputedStyle(el).backdropFilter) {
                            el.style.backdropFilter = 'none';
                        }
                    });
                }
                removeElements();
                // Run again after a delay to catch dynamic elements
                setTimeout(removeElements, 500);
            """

            try:
                driver.get(url.strip())
            except:
                logger.warning(f"Initial load failed for {url}, retrying with stop...")
                driver.execute_script("window.stop();")
                driver.get(url.strip())

            # Execute stealth scripts
            driver.execute_script(stealth_js)
            
            # Wait for content to load
            time.sleep(2)
            
            # Scroll to ensure all content is loaded
            driver.execute_script("window.scrollTo(0, 0);")
            time.sleep(0.5)
            driver.execute_script("window.scrollTo(0, document.body.scrollHeight);")
            time.sleep(0.5)
            driver.execute_script("window.scrollTo(0, 0);")
            
            # Remove popups and overlays
            driver.execute_script(remove_elements_js)
            time.sleep(1)  # Wait for removals to complete

            # Handle Reddit-specific elements
            if 'reddit.com' in url:
                reddit_js = """
                    // Remove Reddit's specific overlays and popups
                    document.querySelectorAll('[data-testid="content-gate"]').forEach(e => e.remove());
                    document.querySelectorAll('[data-testid="login-gate"]').forEach(e => e.remove());
                    document.querySelectorAll('#SHORTCUT_FOCUSABLE_DIV > div:last-child').forEach(e => {
                        if (e.querySelector('[data-testid="overlay"]')) e.remove();
                    });
                """
                driver.execute_script(reddit_js)
                time.sleep(0.5)

            # Take screenshot with proper viewport
            viewport_js = f"return Math.max(document.documentElement.clientHeight, {self.height});"
            height = driver.execute_script(viewport_js)
            driver.set_window_size(self.width, height)
            
            png_data = driver.get_screenshot_as_png()
            driver.quit()

            # Process image
            pil_img = Image.open(io.BytesIO(png_data)).convert("RGB")
            return self._fit_image(pil_img, self.width, self.height)

        except Exception as e:
            logger.error(f"Enhanced screenshot failed => {e}")
            return np.zeros((self.height, self.width, 3), dtype=np.uint8)

    def _fit_image(self, pil_img: Image.Image, tw: int, th: int) -> np.ndarray:
        """
        Fit a PIL image into (tw,th) with black padding, preserving aspect ratio.
        """
        orig_w, orig_h = pil_img.size
        ratio = min(tw / orig_w, th / orig_h)
        new_w = int(orig_w * ratio)
        new_h = int(orig_h * ratio)

        resized = pil_img.resize((new_w, new_h), Image.LANCZOS)
        bkg = Image.new("RGB", (tw, th), (0, 0, 0))
        off_x = (tw - new_w)//2
        off_y = (th - new_h)//2
        bkg.paste(resized, (off_x, off_y))
        bgr = cv2.cvtColor(np.array(bkg), cv2.COLOR_RGB2BGR)
        return bgr

    def get_frame(self, path_or_url: str) -> np.ndarray:
        """
        Decide if 'path_or_url' is an http(s) URL or a local file.
        Return the fitted BGR frame. 
        """
        candidate = path_or_url.strip()
        if not candidate:
            return np.zeros((self.height, self.width, 3), dtype=np.uint8)

        # If it looks like a URL, screenshot with Selenium, else treat as local image file
        if self.is_url(candidate):
            return self.screenshot_url(candidate)
        else:
            return self.load_local_image(candidate)

    def combine_two_audios(self, main_audio: str, bg_audio: str, out_audio: str) -> bool:
        """
        Combine two audio tracks: main_audio (TTS speech) + bg_audio (music).
        We'll lower the bg music volume to ~0.2 so it doesn't overpower speech.
        Output a single track (out_audio).

        Using FFmpeg filter_complex amix:
          [1:a]volume=0.2[a1];[0:a][a1]amix=inputs=2:duration=first[aout]
        """
        cmd = [
            "ffmpeg","-y",
            "-i", main_audio,
            "-i", bg_audio,
            "-filter_complex",
            "[1:a]volume=0.2[a1];[0:a][a1]amix=inputs=2:duration=first:dropout_transition=2[aout]",
            "-map","[aout]",
            "-c:a","aac",
            "-b:a","192k",
            out_audio
        ]
        logger.info(f"Combining TTS + BG music => {cmd}")
        r = subprocess.run(cmd, capture_output=True, text=True)
        if r.returncode != 0:
            logger.error(f"Audio combine error => {r.stderr}")
            return False
        if not os.path.exists(out_audio):
            logger.error("Combined audio file not created.")
            return False
        return True

    def _merge_final(self, silent_mp4: str, final_audio: str, output_mp4: str) -> bool:
        """
        Merge final audio with the silent Ken Burns MP4.
        Using h264_nvenc (switch to libx264 if no GPU).
        """
        cmd = [
            "ffmpeg","-y",
            "-i", silent_mp4,
            "-i", final_audio,
            "-c:v","h264_nvenc",
            "-preset","p4",
            "-rc","vbr",
            "-cq","32",
            "-b:v","0",
            "-pix_fmt","yuv420p",
            "-c:a","aac",
            "-ar","48000",
            "-b:a","192k",
            "-strict","-2",
            "-map","0:0",
            "-map","1:0",  # Ensure that the second input (final_audio) is mapped to audio
            output_mp4
        ]
        logger.info(f"Merging final audio => {cmd}")
        rr = subprocess.run(cmd, capture_output=True, text=True)
        if rr.returncode != 0:
            logger.error(f"Final merge error => {rr.stderr}")
            return False
        return True

    def build_kenburns_silent(
        self,
        paragraphs: List[str],
        paths_or_urls: List[str],
        segment_durations: List[float],
        total_audio_dur: float = 0.0,
        final_out: str = None
    ) -> str:
        """
        Build a SILENT Ken Burns MP4 (60fps). Returns path to that silent mp4.
        Uses exact durations from TTS generation for each segment.
        """
        output_folder = os.path.dirname(final_out) if final_out else "/tmp"
        
        # Use the pre-calculated segment durations from TTS
        seg_durations = segment_durations
        num_segments = len(seg_durations)

        # Grab frames - one for each paragraph/segment
        frames = []
        for idx in range(num_segments):
            # Use corresponding image, or last available image if we run out
            image_idx = min(idx, len(paths_or_urls) - 1) if paths_or_urls else 0
            if paths_or_urls:
                f = self.get_frame(paths_or_urls[image_idx])
                frames.append(f)
        
        if not frames:
            logger.error("No frames available!")
            return ""

        # Build silent mp4
        silent_mp4_path = self._create_temp_file(".mp4", output_folder)

        fourcc = cv2.VideoWriter_fourcc(*'mp4v')
        out = cv2.VideoWriter(silent_mp4_path, fourcc, self.fps, (self.width, self.height))
        if not out.isOpened():
            logger.error("VideoWriter open failed.")
            return ""

        def ken_burns_zoom(bgr: np.ndarray, segdur: float, zoom_in=True):
            frames_needed = int(segdur*self.fps)
            if frames_needed<1:
                frames_needed=1

            start_scale = 1.0
            end_scale = 1.05 if zoom_in else 0.95
            if zoom_in:
                sx, ex = 0.0, 0.03
                sy, ey = 0.0, 0.03
            else:
                sx, ex = 0.03, 0.0
                sy, ey = 0.03, 0.0

            if bgr is None or bgr.size==0:
                black = np.zeros((self.height,self.width,3), dtype=np.uint8)
                for _ in range(frames_needed):
                    out.write(black)
                return

            # safe
            bgr = cv2.resize(bgr,(self.width,self.height))
            for i in range(frames_needed):
                alpha = i/(frames_needed-1) if frames_needed>1 else 1
                ease = 0.5 - 0.5*np.cos(alpha*np.pi)
                scale = start_scale+(end_scale-start_scale)*ease

                w_scaled=int(self.width*scale)
                h_scaled=int(self.height*scale)
                w_scaled=max(self.width,w_scaled)
                h_scaled=max(self.height,h_scaled)

                px=sx+(ex-sx)*ease
                py=sy+(ey-sy)*ease

                big=cv2.resize(bgr,(w_scaled,h_scaled),interpolation=cv2.INTER_CUBIC)
                off_x=int((w_scaled-self.width)*px)
                off_y=int((h_scaled-self.height)*py)
                off_x=max(0,min(off_x,w_scaled-self.width))
                off_y=max(0,min(off_y,h_scaled-self.height))
                    
                crop=big[off_y:off_y+self.height, off_x:off_x+self.width]
                if crop.shape[:2]!=(self.height,self.width):
                    crop=cv2.resize(crop,(self.width,self.height))
                out.write(crop)

        # Alternate zoom in/out for each paragraph
        segcount = len(seg_durations)
        for idx, segdur in enumerate(seg_durations):
            fidx = idx%len(frames)
            frame_bgr = frames[fidx]
            if idx%2==0:
                ken_burns_zoom(frame_bgr, segdur, zoom_in=True)
            else:
                ken_burns_zoom(frame_bgr, segdur, zoom_in=False)

        out.release()
        return silent_mp4_path

    def build_video_with_optional_music(
        self,
        paragraphs: List[str],
        paths_or_urls: List[str],
        final_out: str,
        transitions: Optional[List[float]] = None,
        uniform_dur: Optional[float] = None,
        bg_music_path: Optional[str] = None
    ) -> bool:
        """
        Build the final video with optional background music.

        This method handles the creation of TTS segments, concatenates them,
        optionally mixes with background music, and merges the final audio with the video.

        Args:
            paragraphs (List[str]): List of script paragraphs.
            paths_or_urls (List[str]): List of background image paths or URLs.
            final_out (str): Output path for the final video.
            transitions (Optional[List[float]]): Optional list of transition timestamps.
            uniform_dur (Optional[float]): Optional uniform transition duration.
            bg_music_path (Optional[str]): Optional path to background music file.

        Returns:
            bool: True if video creation is successful, False otherwise.
        """
        output_folder = os.path.dirname(final_out)
        try:
            # Ensure the output folder path is absolute and create it if it doesn't exist
            output_folder = os.path.abspath(output_folder)
            os.makedirs(output_folder, exist_ok=True)

            # Generate TTS for each paragraph and get exact durations
            segment_durations = []
            tts_segments = []
            total_duration = 0.0

            for i, paragraph in enumerate(paragraphs):
                # Generate TTS for this paragraph
                temp_tts = self._create_temp_file(".wav", output_folder)

                success, duration = generate_tts_kokoro(paragraph, temp_tts, return_duration=True)
                if not success:
                    logger.error(f"Failed to generate TTS for paragraph {i}")
                    self.cleanup_temp_files()
                    return False

                # Convert temp_tts to absolute path with forward slashes
                abs_tts_path = os.path.abspath(temp_tts).replace('\\', '/')
                tts_segments.append(abs_tts_path)
                segment_durations.append(duration)
                total_duration += duration

            # Concatenate all TTS segments into final audio
            concat_list = self._create_temp_file(".txt", output_folder)
            with open(concat_list, 'w', encoding='utf-8') as f:
                for segment in tts_segments:
                    # Ensure paths are absolute and properly escaped
                    abs_segment = os.path.abspath(segment).replace('\\', '/')
                    f.write(f"file '{abs_segment}'\n")

            final_tts = os.path.abspath(self._create_temp_file(".wav", output_folder)).replace('\\', '/')

            # FFmpeg command to concatenate TTS segments
            cmd_concat = [
                "ffmpeg",
                "-y",
                "-f", "concat",
                "-safe", "0",
                "-i", concat_list,
                "-c", "copy",
                final_tts
            ]
            logger.info(f"Concatenating TTS segments => {cmd_concat}")
            proc_concat = subprocess.run(cmd_concat, capture_output=True, text=True)

            if proc_concat.returncode != 0:
                logger.error(f"FFmpeg concat error => {proc_concat.stderr}")
                self.cleanup_temp_files()
                return False

            if not os.path.exists(final_tts):
                logger.error("Final TTS audio file not created!")
                self.cleanup_temp_files()
                return False

            # Build silent video with exact durations
            update_progress("working", "Building silent Ken Burns video...", 30)
            silent_mp4 = self.build_kenburns_silent(
                paragraphs=paragraphs,
                paths_or_urls=paths_or_urls,
                segment_durations=segment_durations,
                total_audio_dur=total_duration,
                final_out=final_out
            )

            if not silent_mp4 or not os.path.exists(silent_mp4):
                logger.error("Ken Burns silent video not created or empty.")
                self.cleanup_temp_files()
                return False

            # Handle background music and final merge
            final_audio = final_tts  # Default to TTS only
            if bg_music_path and os.path.exists(bg_music_path):
                bg_music_abs = os.path.abspath(bg_music_path).replace('\\', '/')
                logger.info("Background music provided => merging TTS + music.")
                combined_temp = self._create_temp_file(".wav", output_folder)

                # FFmpeg command to mix TTS with background music
                # Background music volume set to 0.25 (25%) for standard audibility
                cmd_mix = [
                    "ffmpeg",
                    "-y",
                    "-i", final_tts,
                    "-i", bg_music_abs,
                    "-filter_complex",
                    (
                        "[1:a]aformat=channel_layouts=stereo:sample_fmts=fltp:sample_rates=44100,volume=0.25,afade=t=in:ss=0:d=2,afade=t=out:st=duration-2:d=2[a1];"
                        "[0:a]aformat=channel_layouts=stereo:sample_fmts=fltp:sample_rates=44100[a0];"
                        "[a0][a1]amix=inputs=2:duration=first:dropout_transition=2[aout]"
                    ),
                    "-map", "[aout]",
                    "-c:a", "aac",
                    "-b:a", "192k",
                    combined_temp
                ]
                logger.info(f"Merging TTS with background music => {cmd_mix}")
                proc_mix = subprocess.run(cmd_mix, capture_output=True, text=True)

                if proc_mix.returncode != 0:
                    logger.error(f"FFmpeg audio mix error => {proc_mix.stderr}")
                    # Fallback to TTS only if mixing fails
                else:
                    logger.info("Background music successfully mixed with TTS.")
                    final_audio = combined_temp

            # Final merge of audio with silent video
            update_progress("working", "Merging final audio track...", 70)
            success = self._merge_final(silent_mp4, final_audio, final_out)

            if not success:
                logger.error("Final merge of audio and video failed.")
                self.cleanup_temp_files()
                return False

            # Cleanup all temp files after successful generation
            self.cleanup_temp_files()
            logger.info(f"Video successfully created at {final_out}")
            update_progress("done", f"Success! Output => {final_out}", 100)
            return True

        except Exception as e:
            logger.error(f"Error in build_video_with_optional_music: {e}")
            # Cleanup on error
            self.cleanup_temp_files()
            update_progress("error", "An unexpected error occurred during video creation.", 100)
            return False
# ---------------------------------------------------------------------------
# FastAPI App
# ---------------------------------------------------------------------------
app = FastAPI()

@app.get("/", response_class=HTMLResponse)
async def index():
    """
    Main advanced UI with:
      - Folder picking (Ubuntu)
      - Drag+drop paragraphs
      - Reordering links or local image paths
      - 60fps Ken Burns
      - Optional background MP3
    """
    html_content = r'''
<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <title>Super Badass Video Editor with Optional BGM</title>
    <style>
        /* Basic Reset */
        * {
            box-sizing: border-box;
            margin: 0;
            padding: 0;
        }

        body {
            background-color: #121212;
            color: #E0E0E0;
            font-family: Arial, sans-serif;
            padding: 20px;
        }

        .container {
            max-width: 1200px;
            margin: auto;
            background-color: #1E1E1E;
            padding: 30px;
            border-radius: 8px;
        }

        h1, h2, h3 {
            color: #f0f0f0;
            margin-bottom: 20px;
        }

        label {
            display: block;
            margin-top: 15px;
            font-weight: bold;
        }

        input[type="text"],
        textarea,
        select {
            width: 100%;
            padding: 10px;
            margin-top: 5px;
            background-color: #2b2b2b;
            color: #ccc;
            border: 1px solid #444;
            border-radius: 4px;
        }

        input[type="file"] {
            margin-top: 10px;
        }

        button {
            margin-top: 20px;
            padding: 12px 20px;
            background-color: #3f51b5;
            border: none;
            border-radius: 4px;
            color: #fff;
            font-size: 16px;
            cursor: pointer;
        }

        button:hover {
            background-color: #5c6bc0;
        }

        .dynamic-fields {
            display: flex;
            align-items: center;
            gap: 10px;
            margin-bottom: 10px;
        }

        .dynamic-fields textarea,
        .dynamic-fields input[type="text"] {
            flex: 1;
        }

        .remove-btn {
            background: none;
            border: none;
            color: #ff4444;
            font-size: 20px;
            cursor: pointer;
        }

        .remove-btn:hover {
            color: #ff0000;
        }

        .reorder-handle {
            cursor: move;
            font-size: 20px;
            user-select: none;
            color: #999;
        }

        .reorder-list {
            list-style: none;
            padding: 0;
            margin-top: 10px;
            background-color: #2b2b2b;
            border: 1px solid #444;
            border-radius: 4px;
            min-height: 50px;
        }

        .reorder-list li {
            padding: 10px;
            margin: 5px;
            background-color: #333;
            border-radius: 4px;
            display: flex;
            align-items: center;
            gap: 10px;
            cursor: move;
        }

        .drag-drop-area {
            border: 2px dashed #555;
            border-radius: 6px;
            padding: 40px;
            text-align: center;
            color: #999;
            margin-top: 15px;
            transition: background-color 0.3s, border-color 0.3s;
        }

        .drag-drop-area.drag-over {
            background-color: #2b2b2b;
            border-color: #3f51b5;
            color: #f0f0f0;
        }

        .progress-area {
            margin-top: 30px;
            background-color: #2b2b2b;
            padding: 20px;
            border-radius: 4px;
        }

        .progress-bar-bg {
            width: 100%;
            background-color: #444;
            height: 20px;
            border-radius: 10px;
            overflow: hidden;
            margin-top: 10px;
        }

        .progress-bar-fill {
            height: 100%;
            width: 0%;
            background-color: #3f51b5;
            transition: width 0.3s;
        }

        @media (max-width: 768px) {
            .container {
                padding: 20px;
            }
        }
    </style>
    <script>
        // Drag and Drop functionality for reordering
        let dragSrcEl = null;

        function handleDragStart(e) {
            dragSrcEl = this;
            e.dataTransfer.effectAllowed = 'move';
            e.dataTransfer.setData('text/html', this.innerHTML);
            this.classList.add('dragging');
        }

        function handleDragOver(e) {
            if (e.preventDefault) {
                e.preventDefault();
            }
            e.dataTransfer.dropEffect = 'move';
            return false;
        }

        function handleDragEnter(e) {
            this.classList.add('drag-over');
        }

        function handleDragLeave(e) {
            this.classList.remove('drag-over');
        }

        function handleDrop(e) {
            if (e.stopPropagation) {
                e.stopPropagation();
            }

            if (dragSrcEl !== this) {
                // Swap the content and values
                const srcContent = dragSrcEl.innerHTML;
                const destContent = this.innerHTML;

                dragSrcEl.innerHTML = destContent;
                this.innerHTML = srcContent;

                // Reattach event listeners to the new elements
                attachDragListeners(dragSrcEl);
                attachDragListeners(this);
            }

            this.classList.remove('drag-over');
            return false;
        }

        function handleDragEnd(e) {
            this.classList.remove('dragging');
            document.querySelectorAll('.drag-over').forEach(elem => {
                elem.classList.remove('drag-over');
            });
        }

        function attachDragListeners(element) {
            element.addEventListener('dragstart', handleDragStart, false);
            element.addEventListener('dragenter', handleDragEnter, false);
            element.addEventListener('dragover', handleDragOver, false);
            element.addEventListener('dragleave', handleDragLeave, false);
            element.addEventListener('drop', handleDrop, false);
            element.addEventListener('dragend', handleDragEnd, false);
        }

        // Folder Selection
        async function pickFolder() {
            try {
                if ('showDirectoryPicker' in window) {
                    const dirHandle = await window.showDirectoryPicker();
                    const dirPath = dirHandle.name;
                    document.getElementById('outputFolder').value = dirPath;
                    return;
                }
            } catch (err) {
                console.log("Modern folder picker failed, falling back to input method");
            }

            const input = document.getElementById('folderPicker');
            input.value = '';
            input.setAttribute("directory", "");
            input.setAttribute("webkitdirectory", "");
            input.setAttribute("mozdirectory", "");
            input.click();
        }

        function folderPicked(evt) {
            const files = evt.target.files;
            if (files.length > 0) {
                let path = files[0].webkitRelativePath || files[0].mozFullPath || files[0].path;
                let folderPath = path.split('/')[0];

                if (files[0].path) {
                    folderPath = files[0].path.substring(0, files[0].path.lastIndexOf('\\'));
                }

                if (navigator.platform.indexOf('Win') !== -1) {
                    folderPath = folderPath.replace(/\//g, '\\');
                } else if (navigator.platform.indexOf('Mac') !== -1) {
                    folderPath = '/Users/' + folderPath;
                } else {
                    folderPath = '/home/' + folderPath;
                }

                document.getElementById('outputFolder').value = folderPath;
                localStorage.setItem('lastOutputFolder', folderPath);
            }
        }

        // Add paragraph functionality
        function addParagraph() {
            const container = document.getElementById('paragraphsContainer');
            const div = document.createElement('div');
            div.classList.add('dynamic-fields');
            div.setAttribute('draggable', 'true');

            div.innerHTML = `
                <span class="reorder-handle">&#9776;</span>
                <textarea name="paragraphs" rows="3" placeholder="Enter script paragraph here"></textarea>
                <button type="button" class="remove-btn" onclick="removeParagraph(this)">×</button>
            `;

            container.appendChild(div);
            attachDragListeners(div);
        }

        // Add background segment functionality
        function addBackgroundSegment() {
            const list = document.getElementById('linksList');
            const li = document.createElement('li');
            li.setAttribute('draggable', 'true');

            li.innerHTML = `
                <span class="reorder-handle">&#9776;</span>
                <input type="text" class="link-input" name="links" placeholder="Enter link or image path">
                <button type="button" class="remove-btn" onclick="removeBackgroundSegment(this)">×</button>
            `;

            list.appendChild(li);
            attachDragListeners(li);
        }

        // Remove functions
        function removeParagraph(button) {
            button.closest('.dynamic-fields').remove();
        }

        function removeBackgroundSegment(button) {
            button.closest('li').remove();
        }

        // Handle text file drop for paragraphs
        function handleTextFileDrop(e) {
            e.preventDefault();
            e.stopPropagation();

            const dt = e.dataTransfer;
            const files = dt.files;

            if (files.length > 0) {
                const file = files[0];
                if (!file.name.toLowerCase().endsWith('.txt')) {
                    alert("Please drop a .txt file for paragraphs!");
                    return;
                }

                const reader = new FileReader();
                reader.onload = function(evt) {
                    const text = evt.target.result;
                    const paras = text.split(/\n\n+/);
                    const container = document.getElementById('paragraphsContainer');
                    container.innerHTML = '';

                    paras.forEach(p => {
                        if (p.trim()) {
                            const div = document.createElement('div');
                            div.classList.add('dynamic-fields');
                            div.setAttribute('draggable', 'true');
                            div.innerHTML = `
                                <span class="reorder-handle">&#9776;</span>
                                <textarea name="paragraphs" rows="3">${p.trim()}</textarea>
                                <button type="button" class="remove-btn" onclick="removeParagraph(this)">×</button>
                            `;
                            container.appendChild(div);
                            attachDragListeners(div);
                        }
                    });
                };
                reader.readAsText(file);
            }
        }

        // Generate Video Function
        async function generateVideo(event) {
            event.preventDefault();
            const form = document.getElementById('genForm');
            const formData = new FormData(form);

            // Update progress UI
            document.getElementById('progressMessage').innerText = "Uploading...";
            document.querySelector('.progress-bar-fill').style.width = '10%';

            try {
                const response = await fetch('/generate_video', {
                    method: 'POST',
                    body: formData
                });

                const result = await response.json();

                if (response.ok && !result.error) {
                    const taskId = result.task_id;
                    document.getElementById('progressMessage').innerText = "Processing...";
                    document.querySelector('.progress-bar-fill').style.width = '30%';

                    // Poll for progress
                    const interval = setInterval(async () => {
                        const progressRes = await fetch(`/progress?task_id=${taskId}`);
                        const progress = await progressRes.json();

                        // Update progress bar and message
                        document.getElementById('progressMessage').innerText = progress.message;
                        document.querySelector('.progress-bar-fill').style.width = `${progress.pct}%`;

                        if (progress.status === "done" || progress.status === "error") {
                            clearInterval(interval);
                            if (progress.status === "done") {
                                alert(`Video created successfully! Output file: ${progress.message}`);
                                document.getElementById('progressMessage').innerText = "Success!";
                            } else {
                                alert(`Error: ${progress.message}`);
                                document.getElementById('progressMessage').innerText = "Error!";
                            }
                        }
                    }, 2000);
                } else {
                    alert(`Error: ${result.error}`);
                    document.getElementById('progressMessage').innerText = "Error!";
                    document.querySelector('.progress-bar-fill').style.width = '100%';
                }
            } catch (error) {
                console.error('Error:', error);
                alert('An unexpected error occurred.');
                document.getElementById('progressMessage').innerText = "Error!";
                document.querySelector('.progress-bar-fill').style.width = '100%';
            }
        }

        // Initialize on page load
        document.addEventListener('DOMContentLoaded', () => {
            // Restore last used folder
            try {
                const lastFolder = localStorage.getItem('lastOutputFolder');
                if (lastFolder) {
                    document.getElementById('outputFolder').value = lastFolder;
                }
            } catch (e) {
                console.log('Could not restore last folder');
            }

            // Initialize drag and drop for existing elements
            document.querySelectorAll('.dynamic-fields, #linksList li').forEach(elem => {
                attachDragListeners(elem);
            });

            // Set up drag and drop zone for text files
            const dropZone = document.querySelector('.drag-drop-area');
            dropZone.addEventListener('dragover', e => {
                e.preventDefault();
                dropZone.classList.add('drag-over');
            });
            dropZone.addEventListener('dragleave', e => {
                dropZone.classList.remove('drag-over');
            });
            dropZone.addEventListener('drop', e => {
                dropZone.classList.remove('drag-over');
                handleTextFileDrop(e);
            });

            // Attach generateVideo to form submission
            const form = document.getElementById('genForm');
            form.addEventListener('submit', generateVideo);
        });
    </script>
</head>
<body>
    <div class="container">
        <h1>Super Badass Video Editor</h1>
        <form id="genForm" method="POST" enctype="multipart/form-data">

            <!-- Output Folder -->
            <label for="outputFolder">Output Folder (Ubuntu only)</label>
            <div style="display:flex; gap:10px;">
                <input type="text" name="output_folder" id="outputFolder" placeholder="/home/ubuntu/videos" style="flex:1;">
                <button type="button" onclick="pickFolder()">Select Folder</button>
            </div>
            <small>Note: Folder selection is only fully supported on Ubuntu. On other OS, manually enter the path.</small>

            <!-- Output Video Name -->
            <label for="outputName">Output Video Name</label>
            <input type="text" name="output_name" id="outputName" placeholder="myvideo.mp4">

            <!-- Script Paragraphs -->
            <h3>Script Paragraphs</h3>
            <div class="drag-drop-area">
                Drop a .txt file here to populate paragraphs
            </div>
            <div id="paragraphsContainer">
                <div class="dynamic-fields" draggable="true">
                    <span class="reorder-handle">&#9776;</span>
                    <textarea name="paragraphs" rows="3" placeholder="Enter script paragraph here"></textarea>
                    <button type="button" class="remove-btn" onclick="removeParagraph(this)">×</button>
                </div>
            </div>
            <button type="button" onclick="addParagraph()">+ Add Paragraph</button>

            <!-- Reorderable Backgrounds -->
            <h3>Reorderable Backgrounds (Links or Local Image Paths)</h3>
            <ul class="reorder-list" id="linksList">
                <li draggable="true">
                    <span class="reorder-handle">&#9776;</span>
                    <input type="text" class="link-input" name="links" placeholder="Enter link or image path">
                    <button type="button" class="remove-btn" onclick="removeBackgroundSegment(this)">×</button>
                </li>
            </ul>
            <button type="button" onclick="addBackgroundSegment()">+ Add Background Segment</button>

            <!-- Optional Timestamps -->
            <label for="timestamps">Optional Timestamps (comma-separated)</label>
            <input type="text" name="timestamps" id="timestamps" placeholder="0,5,10,...">

            <!-- Uniform Transition Duration -->
            <label for="transition_duration">Uniform Transition Duration (seconds) - If blank => auto-spread by paragraph length</label>
            <input type="text" name="transition_duration" id="transition_duration" placeholder="">

            <!-- Resolution Selection -->
            <label for="resolution">Resolution & Orientation</label>
            <select name="resolution" id="resolution">
                <option value="1280x720">HD (1280x720)</option>
                <option value="720x1280">HD Portrait (720x1280)</option>
                <option value="1920x1080" selected>Full HD (1920x1080)</option>
                <option value="1080x1920">Full HD Portrait (1080x1920)</option>
            </select>

            <!-- Optional Background Music -->
            <h3>Background Music (Optional)</h3>
            <label for="bg_music">Upload a .mp3, .wav, or other audio file for background music (will be mixed under TTS)</label>
            <input type="file" name="bg_music" id="bg_music" accept="audio/*,.mp3,.wav,.ogg,.aac,.m4a">

            <!-- Submit Button -->
            <button type="submit">Generate Video</button>
        </form>

        <!-- Progress Area -->
        <div class="progress-area">
            <div id="progressMessage">Idle...</div>
            <div class="progress-bar-bg">
                <div class="progress-bar-fill"></div>
            </div>
        </div>

        <!-- Hidden Input for Folder Picking (Ubuntu only) -->
        <input type="file" id="folderPicker" webkitdirectory directory multiple style="display:none" onchange="folderPicked(event)">
    </div>
</body>
</html>
    '''
    return HTMLResponse(html_content)

@app.post("/generate_video")
async def generate_video(request: Request):
    task_id = datetime.now().strftime("%Y%m%d%H%M%S%f")
    update_progress("working", "Starting up...", 1)

    try:
        # Parse the incoming form data
        form = await request.form()

        # 1) Basic fields
        output_folder = form.get("output_folder") or "/tmp"
        output_name = form.get("output_name") or ""
        paragraphs = form.getlist("paragraphs")
        links = form.getlist("links")
        timestamps_str = form.get("timestamps") or ""
        transition_str = form.get("transition_duration") or ""
        resolution = form.get("resolution") or "1920x1080"

        logger.info(f"Output Folder: {output_folder}")
        logger.info(f"Output Name: {output_name}")
        logger.info(f"Number of Paragraphs: {len(paragraphs)}")
        logger.info(f"Number of Links/Images: {len(links)}")
        logger.info(f"Resolution: {resolution}")
        logger.info(f"Timestamps: {timestamps_str}")
        logger.info(f"Transition Duration: {transition_str}")

        # 2) Parse Resolution
        try:
            w, h = map(int, resolution.lower().split('x'))
            logger.info(f"Parsed Resolution: Width={w}, Height={h}")
        except Exception as e:
            w, h = 1920, 1080
            logger.warning(f"Invalid resolution format '{resolution}'. Using default 1920x1080.")

        # 3) Parse Timestamps
        parsed_timestamps = None
        if timestamps_str.strip():
            try:
                parsed_timestamps = [float(x.strip()) for x in timestamps_str.split(",") if x.strip()]
                logger.info(f"Parsed Timestamps: {parsed_timestamps}")
            except:
                logger.warning(f"Could not parse timestamps '{timestamps_str}'")

        # 4) Parse Uniform Duration
        uniform_dur = None
        if transition_str.strip():
            try:
                uniform_dur = float(transition_str.strip())
                logger.info(f"Uniform Duration: {uniform_dur}")
            except:
                logger.warning(f"Invalid transition duration '{transition_str}'")

        # 5) Handle Background Music
        bg_music_path = None
        try:
            bg_music = form.get("bg_music")
            if isinstance(bg_music, UploadFile) and bg_music.filename:
                logger.info(f"Processing background music file: {bg_music.filename}")

                # Create temp directory if needed
                temp_dir = os.path.abspath(output_folder)
                os.makedirs(temp_dir, exist_ok=True)

                # Generate unique filename with original extension
                file_ext = os.path.splitext(bg_music.filename)[1]
                if not file_ext:
                    file_ext = '.mp3'  # Default to .mp3 if no extension
                bg_music_path = os.path.join(temp_dir, f"temp_bgm_{task_id}{file_ext}")

                # Read and save the file
                content = await bg_music.read()
                if content:  # Verify we have content
                    with open(bg_music_path, "wb") as f:
                        f.write(content)

                    # Verify file was saved successfully
                    if os.path.exists(bg_music_path) and os.path.getsize(bg_music_path) > 0:
                        logger.info(f"Background music saved successfully at: {bg_music_path}")
                    else:
                        logger.error("Background music file is empty or not saved properly")
                        bg_music_path = None
                else:
                    logger.error("No content in uploaded background music file")
                    bg_music_path = None
            else:
                logger.info("No background music file provided")
        except Exception as e:
            logger.error(f"Failed to process background music: {str(e)}")
            bg_music_path = None


        # 6) Build Final Output Path
        if not output_name.strip():
            dt_str = datetime.now().strftime("%Y%m%d_%H%M%S")
            output_name = f"video_{dt_str}.mp4"
            logger.info(f"No output name provided. Using default: {output_name}")
        elif not output_name.lower().endswith(".mp4"):
            output_name += ".mp4"
            logger.info(f"Output name does not end with .mp4. Updated to: {output_name}")

        if not os.path.exists(output_folder):
            try:
                os.makedirs(output_folder, exist_ok=True)
                logger.info(f"Created output folder: {output_folder}")
            except Exception as e:
                logger.error(f"Could not create output folder '{output_folder}': {e}")
                update_progress("error", "Could not create output folder.", 100)
                return {"error": "Could not create output folder.", "task_id": task_id}

        final_path = os.path.join(output_folder, output_name)
        logger.info(f"Final video path: {final_path}")

        # 7) Build Video
        builder = KenBurnsVideoBuilder(width=w, height=h, fps=60)
        try:
            # Log background music status before video generation
            if bg_music_path:
                logger.info(f"Attempting video generation with background music: {bg_music_path}")
            else:
                logger.info("Attempting video generation without background music")

            success = builder.build_video_with_optional_music(
                paragraphs=paragraphs,
                paths_or_urls=links,
                final_out=final_path,
                transitions=parsed_timestamps,
                uniform_dur=uniform_dur,
                bg_music_path=bg_music_path
            )

            # Clean up temporary background music file
            if bg_music_path and os.path.exists(bg_music_path):
                try:
                    os.remove(bg_music_path)
                    logger.info("Temporary background music file cleaned up")
                except Exception as e:
                    logger.warning(f"Failed to clean up background music file: {e}")

            if not success:
                logger.error("Video creation failed.")
                update_progress("error", "Video creation failed.", 100)
                return {"error": "Video creation failed.", "task_id": task_id}

        except Exception as e:
            logger.error(f"Exception during video building: {e}")
            update_progress("error", "Video building exception.", 100)
            return {"error": "Video building exception.", "task_id": task_id}

        update_progress("done", f"Success! Output => {final_path}", 100)
        return {"task_id": task_id}

    except Exception as e:
        logger.error(f"Exception in /generate_video: {e}")
        update_progress("error", "Unexpected server error.", 100)
        return {"error": "Unexpected server error.", "task_id": task_id}

@app.get("/progress")
def get_progress(task_id: str):
    """
    Return the global progress for demonstration.
    """
    return progress_data

# -----------------------------------------------------------------------------
# Entry
# -----------------------------------------------------------------------------
if __name__=="__main__":
    uvicorn.run("gleamvideo:app", host="0.0.0.0", port=8000, reload=True)
